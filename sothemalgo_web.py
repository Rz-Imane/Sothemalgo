from flask import Flask, render_template, request, jsonify, redirect, url_for 
import pandas as pd
import os
import re
import json
import random
from datetime import datetime, timedelta
import random

# Configuration automatique du r√©pertoire de base
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Mise √† jour des importations
from sothemalgo_grouper import (
    load_ofs_from_file,
    load_bom_from_file,
    load_posts_and_operations_data,
    run_grouping_algorithm,
    smooth_and_schedule_groups,
    write_grouped_needs_to_file,
    HORIZON_H_WEEKS,  # Utilis√© comme param√®tre par d√©faut pour l'horizon
    # Assurez-vous que toutes les autres constantes ou fonctions n√©cessaires sont import√©es
)

def parse_output_file(file_path):
    """Parse le fichier de sortie et retourne les donn√©es structur√©es"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Normaliser les sauts de ligne au cas o√π
        content = content.replace('\\n', '\n')
        groups = []
        unassigned_ofs = []
        
        lines = content.split('\n')
        current_group = None
        in_group = False
        in_unassigned = False
        in_calculated_stocks = False
        
        for line in lines:
            line = line.strip()
            
            # D√©but d'un groupe
            if 'Group ID:' in line:
                if current_group:
                    groups.append(current_group)
                current_group = {
                    'id': line.split('Group ID:')[1].strip().replace('#', '').strip(),
                    'ps_product': '',
                    'time_window': '',
                    'remaining_stock': '',
                    'calculated_stocks': {},
                    'ofs': []
                }
                in_group = True
                in_unassigned = False
                in_calculated_stocks = False
                continue
                
            # Infos du groupe
            if in_group and current_group:
                # ‚ö†Ô∏è ICI : on matche "Produit PS Principal" AVEC ou SANS "(ancre)"
                if 'Produit PS Principal' in line and ':' in line:
                    # on prend tout ce qui est apr√®s le premier ':'
                    current_group['ps_product'] = line.split(':', 1)[1].strip().replace('#', '').strip()
                elif 'Fen√™tre Temporelle:' in line:
                    current_group['time_window'] = line.split('Fen√™tre Temporelle:')[1].strip().replace('#', '').strip()
                elif 'Stock PS Calcul√©:' in line:
                    current_group['remaining_stock'] = line.split('Stock PS Calcul√©:')[1].strip().replace('#', '').strip()
                elif 'Stocks calcul√©s:' in line:
                    in_calculated_stocks = True
                    continue
                elif in_calculated_stocks and line.startswith('#') and ':' in line and 'unit√©s' in line:
                    stock_line = line.replace('#', '').strip()
                    if ':' in stock_line and 'unit√©s' in stock_line:
                        product_part = stock_line.split(':')[0].strip()
                        stock_value = stock_line.split(':')[1].replace('unit√©s', '').strip()
                        try:
                            current_group['calculated_stocks'][product_part] = float(stock_value)
                        except ValueError:
                            current_group['calculated_stocks'][product_part] = 0
                elif line.startswith('#') and 'OFs dans ce Groupe:' in line:
                    in_calculated_stocks = False
                
            # Section OFs non affect√©s
            if 'OFs Non Affect√©s' in line:
                if current_group:
                    groups.append(current_group)
                    current_group = None
                in_group = False
                in_unassigned = True
                in_calculated_stocks = False
                continue
                
            # Lignes d'OFs (donn√©es tabulaires)
            if '\t' in line and not line.startswith('#') and line.count('\t') >= 12:
                parts = line.split('\t')
                
                # Ignorer un √©ventuel header tabul√©
                if parts[0] == 'Part':
                    continue

                if len(parts) >= 13:
                    of_data = {
                        'Part': parts[0],
                        'Description': parts[1],
                        'Order_Code': parts[2],
                        'FG': parts[3],
                        'CAT': parts[4],
                        'US': parts[5],
                        'FS': parts[6],
                        'Qty': parts[7],
                        'X3_Date': parts[8],
                        'GRP_FLG': parts[9] if len(parts) > 9 else '',
                        'Start_Date': parts[10] if len(parts) > 10 else '',
                        'Delay': parts[11] if len(parts) > 11 else '',
                        'remaining_stock': parts[12] if len(parts) > 12 else 'N/A'
                    }

                    # Statut calcul√©
                    if in_unassigned or not of_data.get('GRP_FLG'):
                        of_data['Statut'] = 'Non affect√©'
                    else:
                        of_data['Statut'] = 'Affect√©'
                    
                    # Rattachement
                    if in_unassigned or not of_data.get('GRP_FLG'):
                        unassigned_ofs.append(of_data)
                    elif current_group:
                        current_group['ofs'].append(of_data)
        
        if current_group:
            groups.append(current_group)
            
        # Identifier les groupes AVEC PS (productibles) vs SANS PS
        groups_with_supply = []
        groups_without_supply = []
        
        for group in groups:
            ofs_in_group = group.get('ofs', [])
            ps_product = (group.get('ps_product') or '').strip()
            
            supply_present = False
            if ps_product:
                supply_present = any((of.get('Part') or '').strip() == ps_product for of in ofs_in_group)
            
            # fallback : voir si un OF commence par "PS" (si jamais on a des PSxxx)
            if not supply_present:
                supply_present = any((of.get('Part') or '').startswith('PS') for of in ofs_in_group)
            
            group['has_supply'] = supply_present
            group['has_ps'] = supply_present
            
            if supply_present:
                groups_with_supply.append(group)
            else:
                groups_without_supply.append(group)
        
        # Pour l'affichage, on pr√©f√®re les groupes "productibles" s'il y en a
        groups_for_display = groups_with_supply if groups_with_supply else groups
        
        # OFs vraiment non affect√©s
        truly_unassigned_ofs = list(unassigned_ofs)
        
        # ‚ûú OPTION : si tu veux continuer √† remonter les OFs des groupes sans PS
        # comme "non productibles", tu laisses ce bloc.
        # Sur ton fichier d'exemple, groups_without_supply sera vide apr√®s correction.
        non_productible_ofs_in_groups = []
        for group in groups_without_supply:
            for of in group.get('ofs', []):
                non_productible_ofs_in_groups.append(of)

        return {
            'groups': groups_for_display,
            'unassigned_ofs': truly_unassigned_ofs,
            'non_productible_ofs_in_groups': non_productible_ofs_in_groups
        }
        
    except Exception as e:
        return {'error': f'Erreur lors du parsing du fichier: {str(e)}', 'groups': [], 'unassigned_ofs': []}

            

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = os.path.join(BASE_DIR, 'uploads')
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)



def build_planning_sections(parsed_data):
    """
    Retourne une liste de sections:
    [
      {
        'title': 'Groupe GRP1',
        'subtitle': 'PS: PS123  |  Fen√™tre: 2025-01-01 ‚Üí 2025-01-28',
        'rows': [ {article, num_order, qte_lance, date_besoin, date_proposee, statut_faisable, retard}, ... ]
      },
      {
        'title': 'Non affect√©s',
        'subtitle': 'OF hors groupe',
        'rows': [...]
      }
    ]
    """
    def row_from_of(of):
        part = (of.get('Part') or '').strip()
        order_code = (of.get('Order_Code') or '').strip()
        qty = (of.get('Qty') or '').strip()
        need = (of.get('X3_Date') or '').strip()
        start = (of.get('Start_Date') or '').strip()
        delay = (of.get('Delay') or '').strip()
        try:
            delay_int = int(str(delay).strip() or "0")
        except:
            delay_int = 0
        statut = "OUI" if start and delay_int == 0 else "NON"
        return {
            "article": part,
            "num_order": order_code,
            "qte_lance": qty,
            "date_besoin": need,
            "date_proposee": start or "‚Äî",
            "statut_faisable": statut,
            "retard": str(delay_int),
        }

    sections = []

    # Sections par groupe
    for g in parsed_data.get('groups', []):
        gid = (g.get('id') or '').strip()
        ps = (g.get('ps_product') or '‚Äî').strip()
        window = (g.get('time_window') or '‚Äî').replace('√†', '‚Üí')
        rows = [row_from_of(of) for of in g.get('ofs', [])]
        rows.sort(key=lambda r: (r["date_besoin"], r["num_order"]))
        sections.append({
            "title": f"Groupe {gid}",
            "subtitle": f"PS: {ps}  |  Fen√™tre: {window}",
            "rows": rows
        })

    # Section Non affect√©s
    unassigned = [row_from_of(of) for of in parsed_data.get('unassigned_ofs', [])]
    unassigned.sort(key=lambda r: (r["date_besoin"], r["num_order"]))
    sections.append({
        "title": "Non affect√©s",
        "subtitle": "OF hors groupe",
        "rows": unassigned
    })

    return sections


@app.route("/planning")
def planning_page():
    import json, os
    # if you already have a file you render from, keep it;
    # otherwise we can build rows directly from currently scheduled OFs.
    # Example: read the same JSON built by smooth_and_schedule_groups:
    path = os.path.join(os.getcwd(), "uploads", "smoothing_view.json")
    rows = []
    generated_at = "‚Äî"
    try:
        with open(path, "r", encoding="utf-8") as f:
            payload = json.load(f)
            generated_at = payload.get("generated_at", "‚Äî")
            rows = payload.get("items", [])
    except Exception as e:
        print(f"[planning] cannot read {path}: {e}")

    # ensure every row has the keys you will use in the template
    for r in rows:
        r.setdefault("group_id", "Hors groupe")
        r.setdefault("product_id", "")
        r.setdefault("designation", "")
        r.setdefault("need_date", "")
        r.setdefault("scheduled_start", None)
        r.setdefault("scheduled_end", None)
        r.setdefault("status", "")
        r.setdefault("retard_jours", 0)
        r.setdefault("operations", [])

    return render_template(
        "planning_modern.html",
        generated_at=generated_at,
        rows=rows,          # <- use this in the template
    )



@app.route('/', methods=['GET', 'POST'])
def index():
    if request.method == 'POST':
        action = request.form.get('action', 'run_algorithm')  # ‚Üê ADD

        # R√©cup√©rer les fichiers t√©l√©charg√©s
        besoins_file_storage = request.files.get('besoins_file')
        nomenclature_file_storage = request.files.get('nomenclature_file')
        posts_file_storage = request.files.get('posts_file')
        operations_file_storage = request.files.get('operations_file')
        post_unavailability_file_storage = request.files.get('post_unavailability_file')

        # Utiliser les fichiers par d√©faut ou ceux t√©l√©charg√©s
        base_dir = BASE_DIR
        
        # V√©rifier si l'utilisateur veut utiliser les donn√©es de test
        use_test_data = request.form.get('use_test_data', 'false').lower() == 'true'
        
        # Fichier besoins
        if besoins_file_storage and besoins_file_storage.filename:
            besoins_path = os.path.join(app.config['UPLOAD_FOLDER'], besoins_file_storage.filename)
            besoins_file_storage.save(besoins_path)
        else:
            if use_test_data:
                besoins_path = os.path.join(base_dir, 'test_besoins.csv')
            else:
                # Utiliser par d√©faut les fichiers client depuis uploads/
                besoins_path = os.path.join(app.config['UPLOAD_FOLDER'], 'test_besoins_client.csv')

        # Fichier nomenclature
        if nomenclature_file_storage and nomenclature_file_storage.filename:
            nomenclature_path = os.path.join(app.config['UPLOAD_FOLDER'], nomenclature_file_storage.filename)
            nomenclature_file_storage.save(nomenclature_path)
        else:
            if use_test_data:
                nomenclature_path = os.path.join(base_dir, 'test_nomenclature.csv')
            else:
                # Utiliser par d√©faut les fichiers client depuis uploads/
                nomenclature_path = os.path.join(app.config['UPLOAD_FOLDER'], 'test_nomenclature_client.csv')

        # Fichier posts
        if posts_file_storage and posts_file_storage.filename:
            posts_path = os.path.join(app.config['UPLOAD_FOLDER'], posts_file_storage.filename)
            posts_file_storage.save(posts_path)
        else:
            if use_test_data:
                posts_path = os.path.join(base_dir, 'test_posts.csv')
            else:
                # Utiliser par d√©faut les fichiers client depuis uploads/
                posts_path = os.path.join(app.config['UPLOAD_FOLDER'], 'test_posts_client.csv')

        # Fichier operations
        if operations_file_storage and operations_file_storage.filename:
            operations_path = os.path.join(app.config['UPLOAD_FOLDER'], operations_file_storage.filename)
            operations_file_storage.save(operations_path)
        else:
            if use_test_data:
                operations_path = os.path.join(base_dir, 'test_operations.csv')
            else:
                # Utiliser par d√©faut les fichiers client depuis uploads/
                operations_path = os.path.join(app.config['UPLOAD_FOLDER'], 'test_operations_client.csv')

        # Fichier post_unavailability
        if post_unavailability_file_storage and post_unavailability_file_storage.filename:
            post_unavailability_path = os.path.join(app.config['UPLOAD_FOLDER'], post_unavailability_file_storage.filename)
            post_unavailability_file_storage.save(post_unavailability_path)
        else:
            if use_test_data:
                post_unavailability_path = os.path.join(base_dir, 'test_post_unavailability.csv')
            else:
                # Pour post_unavailability, pas de fichier client, utiliser le fichier principal
                post_unavailability_path = os.path.join(base_dir, 'post_unavailability.csv')
            
        # Param√®tres de lissage (vous pouvez les rendre configurables dans le formulaire)
        try:
            retreat_weeks_val = int(request.form.get('retreat_weeks', '0'))
        except ValueError:
            retreat_weeks_val = 0 # Default if conversion fails
            
        try:
            horizon_weeks_val = int(request.form.get('horizon_weeks', '4'))
        except ValueError:
            horizon_weeks_val = 4 # Default if conversion fails
            
        smoothing_params = {
            'output_file_path': os.path.join(app.config['UPLOAD_FOLDER'], 'besoins_groupes_output_web.txt'),
            'log_file_path': os.path.join(app.config['UPLOAD_FOLDER'], 'sothemalgo_log_web.txt'),
            'retreat_weeks': retreat_weeks_val,
            'auto_mode': request.form.get('auto_mode', 'True').lower() == 'true',
            'advance_retreat_weeks': retreat_weeks_val,  # Utiliser retreat_weeks pour advance_retreat_weeks
            'smoothing_json_path': os.path.join(app.config['UPLOAD_FOLDER'], 'smoothing_view.json')
        }

        # Ex√©cuter l'algorithme
        try:
            # 1. Charger les donn√©es
            all_ofs = load_ofs_from_file(besoins_path)
            if not all_ofs:
                # Changed to warning to allow processing if only warnings are desired
                app.logger.warning(f"Fichier OFs {besoins_path} vide ou √©chec du chargement. Poursuite si possible.")
                # return render_template('index.html', error=f"√âchec du chargement des OFs depuis {besoins_path} ou fichier vide.")


            bom_data = load_bom_from_file(nomenclature_path)
            if not bom_data:
                app.logger.warning(f"Attention: Donn√©es de nomenclature depuis {nomenclature_path} vides ou √©chec du chargement.")
                # Si la nomenclature est absolument requise, vous pouvez lever une erreur ici.

            posts_map, operations_map = load_posts_and_operations_data(
                filepath_posts=posts_path,
                filepath_post_unavailability=post_unavailability_path,
                filepath_operations=operations_path
            )

            # 2. Ex√©cuter l'algorithme de groupement
            # Utiliser une valeur par d√©faut pour horizon_H_weeks_param si non configurable via formulaire
            horizon_weeks = horizon_weeks_val  # Utiliser la valeur du formulaire 
            groups, all_ofs_with_groups = run_grouping_algorithm(
                all_ofs if all_ofs else [], # Pass empty list if loading failed but we continue
                bom_data if bom_data else [], # Pass empty list if loading failed
                horizon_H_weeks_param=horizon_weeks 
            )

            # 3. Ex√©cuter le lissage et la planification
            final_updated_ofs = smooth_and_schedule_groups(
                groups,
                all_ofs_with_groups,
                bom_data if bom_data else [],
                posts_map,
                operations_map,
                params=smoothing_params # Contient output_file_path, log_file_path, etc.
            )
            # 3.2. (NOUVEAU) recalculer les stocks individuels par groupe AVANT d'√©crire
            for g in groups:
                # le nom exact d√©pend de ce que tu as dans sothemalgo_grouper
                # j‚Äôutilise un nom g√©n√©rique que tu avais montr√©
                if hasattr(g, "calculate_consumption"):
                    g.calculate_consumption(bom_data if bom_data else [])
            # 3.5. G√©n√©rer le fichier de sortie
            write_grouped_needs_to_file(smoothing_params['output_file_path'], groups, final_updated_ofs)

            # ‚Üê ADD THIS BLOCK: if the user clicked the Planning button, go to /planning
            if action == 'plan':
                return redirect(url_for('planning_page'))
            
            # 4. Sortie
            output_file_to_read = smoothing_params['output_file_path']
            
            if os.path.exists(output_file_to_read) and os.path.getsize(output_file_to_read) > 0:
                
                # Parser le fichier et retourner les donn√©es structur√©es
                parsed_data = parse_output_file(output_file_to_read)
                
                # For unassigned OFs, we don't need complex stock mapping anymore
                # because individual stock is now included in the output file
                for of in parsed_data.get('unassigned_ofs', []):
                    of['remaining_stock'] = '0.00'

                print("‚úÖ Final parsed data - Individual stocks should be available now")
                print(f"‚úÖ Sample OF data: {parsed_data.get('unassigned_ofs', [])[:1] if parsed_data.get('unassigned_ofs') else 'No unassigned OFs'}")

                return render_template('results_modern.html', 
                                     groups=parsed_data.get('groups', []),
                                     unassigned_ofs=parsed_data.get('unassigned_ofs', []),
                                     error=parsed_data.get('error'))
            else:
                output_content = "L'algorithme a √©t√© ex√©cut√©. "
                if final_updated_ofs:
                    output_content += "Les OFs trait√©s sont disponibles. Affichage brut :\n"
                    output_content += "\n".join([str(of) for of in final_updated_ofs if of is not None])
                elif groups:
                    output_content += "Groupes cr√©√©s mais pas d'OFs finaux apr√®s lissage ou fichier de sortie non g√©n√©r√©.\n"
                    output_content += "\n".join([str(g) for g in groups if g is not None])
                else:
                    output_content += "Aucun OF trait√©, aucun groupe cr√©√© ou aucun fichier de sortie g√©n√©r√©."
                
                return render_template('index_modern.html', output=output_content)

        except Exception as e:
            app.logger.error(f"Erreur durant l'ex√©cution de Sothemalgo: {e}", exc_info=True)
            return render_template('index_modern.html', error=f"Une erreur est survenue: {str(e)}")

    return render_template('index_modern.html')

@app.route('/display-output')
def display_output():
    # Essayer d'abord le fichier g√©n√©r√© par l'interface web (plus r√©cent), puis celui du r√©pertoire courant
    base_dir = BASE_DIR
    web_output_file = os.path.join(app.config['UPLOAD_FOLDER'], 'besoins_groupes_output_web.txt')
    static_output_file = os.path.join(base_dir, 'besoins_groupes_output.txt')
    
    # Choisir le fichier le plus r√©cent ou celui qui existe
    output_file_path = None
    if os.path.exists(web_output_file):
        output_file_path = web_output_file
    elif os.path.exists(static_output_file):
        output_file_path = static_output_file
    
    try:
        if output_file_path and os.path.exists(output_file_path):
            parsed_data = parse_output_file(output_file_path)
            return render_template('results.html', 
                                 groups=parsed_data.get('groups', []),
                                 unassigned_ofs=parsed_data.get('unassigned_ofs', []),
                                 error=parsed_data.get('error'))
        else:
            return render_template('results.html', 
                                 groups=[], 
                                 unassigned_ofs=[], 
                                 error="Aucun fichier de sortie trouv√©. Veuillez ex√©cuter l'algorithme d'abord.")
    except Exception as e:
        return render_template('results.html', 
                             groups=[], 
                             unassigned_ofs=[], 
                             error=f"Erreur lors du chargement du fichier: {str(e)}")

@app.route('/data-visualization')
def data_visualization():
    """Route pour afficher la page de visualisation des donn√©es"""
    return render_template('data_visualization_modern.html')

@app.route('/api/visualization-data')
def get_visualization_data():
    """API endpoint pour r√©cup√©rer les donn√©es de visualisation en temps r√©el"""
    try:
        # Lire les donn√©es des fichiers de sortie existants
        base_dir = BASE_DIR
        
        # Rechercher les fichiers de sortie potentiels et choisir le plus r√©cent
        potential_files = [
            os.path.join(app.config['UPLOAD_FOLDER'], 'besoins_groupes_output_web.txt'),  # Fichier web le plus r√©cent
            os.path.join(base_dir, 'test_besoins_groupes_output.txt'),  # Fichier de test
            os.path.join(base_dir, 'besoins_groupes_output.txt')  # Fichier principal
        ]
        
        # Trouver le fichier existant le plus r√©cent
        output_file_path = None
        latest_time = 0
        
        for file_path in potential_files:
            if os.path.exists(file_path):
                file_time = os.path.getmtime(file_path)
                if file_time > latest_time:
                    latest_time = file_time
                    output_file_path = file_path
        
        # Si aucun fichier de sortie n'existe, g√©n√©rer des donn√©es de d√©monstration
        if output_file_path is None or not os.path.exists(output_file_path):
            return jsonify(generate_demo_visualization_data())
        
        # Parser les donn√©es r√©elles
        parsed_data = parse_output_file(output_file_path)
        visualization_data = process_data_for_visualization(parsed_data)
        
        return jsonify(visualization_data)
        
    except Exception as e:
        # En cas d'erreur, retourner des donn√©es de d√©monstration
        return jsonify(generate_demo_visualization_data())

def process_data_for_visualization(parsed_data):
    """Traite les donn√©es pars√©es pour la visualisation"""
    groups = parsed_data.get('groups', [])
    unassigned_ofs = parsed_data.get('unassigned_ofs', [])
    
    # Calculer les statistiques
    total_groups = len(groups)
    total_ofs = sum(len(group.get('ofs', [])) for group in groups) + len(unassigned_ofs)
    assigned_ofs = total_ofs - len(unassigned_ofs)
    efficiency = (assigned_ofs / total_ofs * 100) if total_ofs > 0 else 0
    
    # Distribution des OFs par groupe
    of_distribution = {}
    for i, group in enumerate(groups[:10]):  # Top 10 groupes
        group_id = group.get('id', f'Groupe {i+1}')
        of_count = len(group.get('ofs', []))
        of_distribution[group_id] = of_count
    
    # Distribution par cat√©gorie (simulation bas√©e sur les donn√©es r√©elles)
    categories = ['Production', 'Assemblage', 'Test', 'Emballage', 'Exp√©dition']
    category_distribution = {}
    for i, category in enumerate(categories):
        category_distribution[category] = len(groups) // len(categories) + (1 if i < len(groups) % len(categories) else 0)
    
    # Efficacit√© par groupe
    group_efficiency = {}
    for group in groups[:8]:  # Top 8 groupes
        group_id = group.get('id', 'Inconnu')
        # Simuler l'efficacit√© bas√©e sur le nombre d'OFs
        of_count = len(group.get('ofs', []))
        group_efficiency[group_id] = min(95, 60 + (of_count * 5))
    
    # Timeline des √©tapes (simul√©e)
    timeline_data = [
        {'step': 'Chargement des donn√©es', 'duration': 2.5, 'status': 'completed'},
        {'step': 'Calcul des groupes', 'duration': 15.3, 'status': 'completed'},
        {'step': 'Optimisation', 'duration': 8.7, 'status': 'completed'},
        {'step': 'Lissage', 'duration': 5.2, 'status': 'completed'},
        {'step': 'G√©n√©ration sortie', 'duration': 1.8, 'status': 'completed'}
    ]
    
    # M√©triques de performance
    performance_metrics = {
        'processing_time': sum(item['duration'] for item in timeline_data),
        'memory_usage': random.randint(45, 85),
        'cpu_usage': random.randint(30, 70),
        'success_rate': efficiency
    }
    
    # Volume de donn√©es par semaine (simulation)
    weeks = [f'S{i+1}' for i in range(12)]
    volume_data = {}
    for week in weeks:
        volume_data[week] = random.randint(50, 200)
    
    return {
        'statistics': {
            'totalGroups': total_groups,
            'totalOfs': total_ofs,
            'assignedOfs': assigned_ofs,
            'efficiency': round(efficiency, 1)
        },
        'ofDistribution': of_distribution,
        'categoryDistribution': category_distribution,
        'groupEfficiency': group_efficiency,
        'timeline': timeline_data,
        'performanceMetrics': performance_metrics,
        'volumeData': volume_data,
        'lastUpdate': datetime.now().isoformat()
    }

def generate_demo_visualization_data():
    """G√©n√®re des donn√©es de d√©monstration pour la visualisation"""
    # Donn√©es de d√©monstration similaires √† celles du template
    return {
        'statistics': {
            'totalGroups': 24,
            'totalOfs': 156,
            'assignedOfs': 142,
            'efficiency': 91.0
        },
        'ofDistribution': {
            'Groupe A': 25,
            'Groupe B': 18,
            'Groupe C': 22,
            'Groupe D': 15,
            'Groupe E': 20,
            'Groupe F': 12,
            'Groupe G': 16,
            'Groupe H': 14
        },
        'categoryDistribution': {
            'Production': 35,
            'Assemblage': 28,
            'Test': 22,
            'Emballage': 18,
            'Exp√©dition': 12
        },
        'groupEfficiency': {
            'Groupe A': 95,
            'Groupe B': 87,
            'Groupe C': 92,
            'Groupe D': 78,
            'Groupe E': 88,
            'Groupe F': 94,
            'Groupe G': 82,
            'Groupe H': 90
        },
        'timeline': [
            {'step': 'Chargement des donn√©es', 'duration': 2.5, 'status': 'completed'},
            {'step': 'Calcul des groupes', 'duration': 15.3, 'status': 'completed'},
            {'step': 'Optimisation', 'duration': 8.7, 'status': 'completed'},
            {'step': 'Lissage', 'duration': 5.2, 'status': 'completed'},
            {'step': 'G√©n√©ration sortie', 'duration': 1.8, 'status': 'completed'}
        ],
        'performanceMetrics': {
            'processing_time': 33.5,
            'memory_usage': 67,
            'cpu_usage': 45,
            'success_rate': 91.0
        },
        'volumeData': {
            'S1': 120, 'S2': 135, 'S3': 95, 'S4': 180, 'S5': 160, 'S6': 145,
            'S7': 170, 'S8': 155, 'S9': 190, 'S10': 175, 'S11': 165, 'S12': 185
        },
        'lastUpdate': datetime.now().isoformat()
    }

@app.route('/api/smoothing')
def api_smoothing():
    """Retourne le lissage (groupes, OFs, op√©rations) en JSON."""
    json_path = os.path.join(app.config['UPLOAD_FOLDER'], 'smoothing_view.json')
    try:
        if os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return jsonify(data)
        return jsonify({"generated_at": None, "items": []})
    except Exception as e:
        return jsonify({"error": str(e), "items": []}), 500


@app.route('/smoothing')
def smoothing_page():
    json_path = os.path.join(app.config['UPLOAD_FOLDER'], 'smoothing_view.json')
    data = {"generated_at": None, "items": []}
    try:
        if os.path.exists(json_path):
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
    except Exception as e:
        data = {"generated_at": None, "items": [], "error": str(e)}
    return render_template('smoothing_modern.html', data=data, items=data.get('items') or [])




@app.route('/test-button')
def test_button():
    """Route de test pour diagnostiquer les probl√®mes de bouton"""
    return render_template('test_button.html')

if __name__ == '__main__':
    # Utiliser waitress comme serveur de production simple et multi-plateforme
    # Mode d√©veloppement local - plus simple √† d√©marrer
    print("üöÄ D√©marrage de l'interface web Sothemalgo...")
    print("üìä Algorithme avec logique de groupement par famille am√©lior√©e")
    print("üåê Interface accessible sur : http://localhost:5000")
    print("‚èπÔ∏è  Appuyez sur Ctrl+C pour arr√™ter")
    app.run(host="127.0.0.1", port=5000, debug=True)
    
    # Pour production avec Waitress (d√©commentez si n√©cessaire) :
    # from waitress import serve
    # serve(app, host="0.0.0.0", port=5002)